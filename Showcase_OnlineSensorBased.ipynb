{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as a showcase for the functions written in the ``wwdata`` package, more specifically the OnlineSensorBased subclass. For additional information on the functions, the user is encouraged to use the provided docstrings. They can be accessed by entering a function name and hitting shift+tab between the function brackets.\n",
    "\n",
    "All information and documentation on the ``wwdata`` package, including how to install it, can also be found online at https://ugentbiomath.github.io/wwdata-docs/.\n",
    "\n",
    "An elaborate explanation on the functionalities of the package is published in *Environmental Modelling & Software* and is available on [ResearchGate](https://www.researchgate.net/publication/325923343_An_open_software_package_for_data_reconciliation_and_gap_filling_in_preparation_of_Water_and_Resource_Recovery_Facility_Modeling)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:55.404080",
     "start_time": "2017-05-09T11:54:53.499498+02:00"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# seaborn is not a required package, it just prettifies the figures\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for the actual package..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wwdata as ww"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what version you have installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.read_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:55.587365",
     "start_time": "2017-05-09T11:54:55.406913+02:00"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "measurements = pd.read_csv('./data/201301.txt',sep='\\t',skiprows=0)\n",
    "measurements.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Class object and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:55.669059",
     "start_time": "2017-05-09T11:54:55.589786+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset = ww.OnlineSensorBased(data=measurements,\n",
    "                               timedata_column='Time',\n",
    "                               data_type='WWTP')\n",
    "dataset.set_tag('January 2013')\n",
    "dataset.replace('Bad','NaN',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the values in the column containing time data to the pandas datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:55.780731",
     "start_time": "2017-05-09T11:54:55.671616+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.to_datetime(time_column=dataset.timename,time_format='%d-%m-%y %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the time-column as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:55.788079",
     "start_time": "2017-05-09T11:54:55.783330+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.set_index('Time',key_is_time=True,drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the absolute timestamps to relative values. This can be important when data is to be used for modeling purposes later on, and needs to be written to text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:55.793662",
     "start_time": "2017-05-09T11:54:55.790638+02:00"
    }
   },
   "outputs": [],
   "source": [
    "#dataset.absolute_to_relative(time_data='index',unit='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop any duplicates that might be present in the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:55.812335",
     "start_time": "2017-05-09T11:54:55.796021+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.drop_index_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all or the selected columns to float type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:56.047638",
     "start_time": "2017-05-09T11:54:55.815534+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.to_float(columns='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:56.758532",
     "start_time": "2017-05-09T11:54:56.050129+02:00"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,4))\n",
    "ax.plot(dataset.data['CODtot_line2'],'.g')\n",
    "ax.set_ylabel('Total COD [mg/L]',fontsize=18);ax.set_xlabel('')\n",
    "ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting data happens through tagging, so no original data is lost. When applying filter algorithms such as ``tag_doubles``, ``moving_slope_filter`` etc., a new pandas dataframe is created (``dataset.meta_valid``, see also below figure) that contains these tags. It is also based on this new dataframe that the plotting of selected and not selected datapoints in different colours happens.\n",
    "\n",
    "![validation](./figs/packagestructure_validation.png)\n",
    "\n",
    "The written output of the filter functions tells the user how many data points were tagged based on that specific function. When the plotting argument is set to true, the plot shows the aggregated results of the filter functions used up until that point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxima\n",
    "Tag the data points that are higher then a certain percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:57.347519",
     "start_time": "2017-05-09T11:54:56.761091+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.get_highs('Flow_total',0.95,arange=['2013/1/1','2013/1/31'],method='percentile',plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN values\n",
    "Tag all NaN (Not a Number) values as 'filtered'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:57.358210",
     "start_time": "2017-05-09T11:54:57.350077+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.tag_nan('CODtot_line2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor failure\n",
    "Tag all datapoints that are part of a constant (within a given bound) signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:57.391744",
     "start_time": "2017-05-09T11:54:57.361076+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.tag_doubles('CODtot_line2',bound=0.05,plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise \n",
    "Tag all data points for which the slope as compared with the previous point is too high to be realistic (i.e. the data point is noisy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:58.312987",
     "start_time": "2017-05-09T11:54:57.394331+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.moving_slope_filter('index','CODtot_line2',72000,arange=['2013/1/1','2013/1/31'],\n",
    "                            time_unit='d',inplace=False,plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag all data points that are more than a specified percentage away from the calculated moving average. This function makes use of the ``simple_moving_average`` function, also written as part of this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:58.360928",
     "start_time": "2017-05-09T11:54:58.315777+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.moving_average_filter(data_name='CODtot_line2',window=12,cutoff_frac=0.20,\n",
    "                              arange=['2013/1/1','2013/1/31'],plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:59.889452",
     "start_time": "2017-05-09T11:54:58.363535+02:00"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = dataset.plot_analysed('CODtot_line2')\n",
    "ax.legend(bbox_to_anchor=(1.15,1.0),fontsize=18)\n",
    "ax.set_ylabel('Total COD [mg/L]',fontsize=18);ax.set_xlabel('')\n",
    "ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a package-specific filtering, data points can also be filtered and replaced by other filtering algorithms, such as the Savitsky-Golay filter as illustrated below. The disadvantage of this is that no tags are added to the ``meta_valid`` DataFrame and that original data are replaced (when the ``inplace`` option is set to ``True``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:54:59.895406",
     "start_time": "2017-05-09T11:54:59.892052+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.savgol('TSS_line3',plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the reliability of the filling algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to make a choice and apply the best method to fill gaps in the data, the ``wwdata`` package provides the option to check for the reliability of each filling algorithm. This is represented in the below figure.\n",
    "\n",
    "![validation](./figs/packagestructure_reliability.png)\n",
    "\n",
    "In wording, the workflow of the ``check_filling_error`` is as follows:\n",
    "* Randomly (!) create large or small artificial gaps in the data within the given ``test_data_range``. \n",
    "* Fill the created gaps with a chosen filling function (see [further in this notebook](#Fill-data) for illustrations of those).\n",
    "* Compare the original data points with the filled data points and calculate the deviation between them.\n",
    "* Iterate for a given number of times, to average out the random creation of the gaps.\n",
    "\n",
    "Before applying this, it is wise to check the total number of points within ``test_data_range`` and then determine the number of gaps to create. Take into account that the length of the gaps is sampled from a uniform distribution between 0 and the maximum length of a gap given as an argument.  \n",
    "For example: creating two large gaps of 50 datapoints in a dataset containing 100 datapoints would mean a theoretical average of 50% data recovery (2*(50/2) = 50 data points are left out of the 100; the 2 gaps can however still overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset.data['2013/1/1':'2013/1/17'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset._filling_warning_issued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.check_filling_error(100,'CODtot_line2','fill_missing_standard',[dt.datetime(2013,1,1,0,5),dt.datetime(2013,1,17)],\n",
    "                            nr_small_gaps=70,max_size_small_gaps=12,\n",
    "                            nr_large_gaps=3,max_size_large_gaps=800,\n",
    "                            to_fill='CODtot_line2',arange=[dt.datetime(2013,1,1,0,5),dt.datetime(2013,1,17)],\n",
    "                            only_checked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.check_filling_error(100,'CODtot_line2','fill_missing_daybefore',[dt.datetime(2013,1,1,0,5),dt.datetime(2013,1,17)],\n",
    "                            nr_small_gaps=70,max_size_small_gaps=12,\n",
    "                            nr_large_gaps=3,max_size_large_gaps=800,\n",
    "                            to_fill='CODtot_line2',arange=[dt.datetime(2013,1,1,0,5),dt.datetime(2013,1,17)],\n",
    "                            range_to_replace=[0,10],only_checked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling data can be done using a range of functions implemented in the package. Again, a new pandas dataframe is created (``dataset.meta_filled``, see also below figure), starting from the ``dataset.meta_valid`` dataframe, and updated with tags indicating what filling method was used to obtain a certain point.\n",
    "\n",
    "![validation](./figs/packagestructure_filling.png)\n",
    "\n",
    "Using the ``only_checked`` argument, implemented in most filling functions, the user can always choose whether only data points tagged as ``filtered`` will be filled, or all data points within a certain range.\n",
    "\n",
    "When using the plotting argument to plot the analysed data, the user will see a plot based on the latest function that was used; if this was a filter function, the data will be plotted based on the ``dataset.meta_valid`` dataframe, if it was a filling function, the tags in ``dataset.meta_filled`` will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation\n",
    "Fill missing data points by interpolation, if number of consecutive missing points is lower than a specified number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:55:01.060520",
     "start_time": "2017-05-09T11:54:59.898063+02:00"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.fill_missing_interpolation('CODtot_line2',12,[dt.datetime(2013,1,1),dt.datetime(2013,1,8)],\n",
    "                                   plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average daily profile\n",
    "Fill missing datapoints by using an average daily profile. The ``fill_missing_standard`` function requires the running of the ``calc_daily_profile`` function, also developed for this package, first. This creates a dataframe (``dataset.daily_profile``) containing the average daily profile calculated within a defined time period (e.g. selecting only non-peak days for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:55:01.103135",
     "start_time": "2017-05-09T11:55:01.063627+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.calc_daily_profile('CODtot_line2',[dt.datetime(2013,1,1),dt.datetime(2013,1,8)],\n",
    "                           quantile=0.9,clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:55:01.844129",
     "start_time": "2017-05-09T11:55:01.105608+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.fill_missing_standard('CODtot_line2',[dt.datetime(2013,1,14),dt.datetime(2013,1,17)],\n",
    "                              only_checked=True,clear=False,plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model output\n",
    "Fill gaps using a model output. This assumes that the user has good reason to trust that the model predictions are sound and can indeed be used to replace missing data where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:55:02.248297",
     "start_time": "2017-05-09T11:55:01.847864+02:00"
    }
   },
   "outputs": [],
   "source": [
    "model_output_ontv_1 = pd.read_csv('./data/model_output.txt',\n",
    "                           sep='\\t')\n",
    "units_model = model_output_ontv_1.iloc[0]\n",
    "model_output_ontv_1 = model_output_ontv_1.drop(0,inplace=False).reset_index(drop=True)\n",
    "model_output_ontv_1 = model_output_ontv_1.astype(float)\n",
    "model_output_ontv_1.set_index('#.t',drop=True,inplace=True)\n",
    "model_output_ontv_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:55:03.902986",
     "start_time": "2017-05-09T11:55:02.251053+02:00"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.fill_missing_model('CODtot_line2',model_output_ontv_1['.sewer_1.COD'],\n",
    "                           [dt.datetime(2013,1,18),dt.datetime(2013,1,22)],\n",
    "                           only_checked=True,plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratio or correlation\n",
    "Constant ratios or correlations between data can be used to filled missing points. The user can calculate and compare ratios and correlations (currently only linear) between selected measurements, and fill data using these.\n",
    "\n",
    "*nb: in the examples below, data filling based on ratios or correlation is obviously not a very good choice. Both methods are included here for completeness of method showcasing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:55:03.917107",
     "start_time": "2017-05-09T11:55:03.905461+02:00"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.calc_ratio('CODtot_line2','CODsol_line2',\n",
    "                   [dt.datetime(2013,1,1,0,5,0),dt.datetime(2013,1,31)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the 'best' ratio (i.e. the one with the lowest relative standard deviation ($\\sigma/\\mu$)), the ratio obtained in different periods can be compared and the best one used during possible further replacements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:55:03.978297",
     "start_time": "2017-05-09T11:55:03.919697+02:00"
    }
   },
   "outputs": [],
   "source": [
    "avg,std = dataset.compare_ratio('CODtot_line2','CODsol_line2',2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the average obtained from the ``compare_ratio`` function to fill in missing values. (*in this case, as mentioned before, this does clearly not work, since zero-values are replaced with zero-values. This only showcases the function and its arguments*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:55:04.632959",
     "start_time": "2017-05-09T11:55:03.980745+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.fill_missing_ratio('CODtot_line2',\n",
    "                           'CODsol_line2',avg,\n",
    "                           [dt.datetime(2013,1,22),dt.datetime(2013,1,23)],\n",
    "                           only_checked=True,plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a ratio, a correlation can be sought. In case of a zero intercept, this of course gives a result in the same range if the same data is used. To have a good impression on how useful the calculated correlation is, a prediction interval is plotted as well when ``plot`` is set to ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_correlation('CODtot_line2',\n",
    "                        'CODsol_line2',\n",
    "                        [dt.datetime(2013,1,1,0,5,0),dt.datetime(2013,1,31)],\n",
    "                        zero_intercept=True,plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the previously made assessment, use the correlation function to fill gaps in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:55:06.016129",
     "start_time": "2017-05-09T11:55:05.261370+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.fill_missing_correlation('CODtot_line2',\n",
    "                                 'CODsol_line2',\n",
    "                                 [dt.datetime(2013,1,23),dt.datetime(2013,1,25)],\n",
    "                                 [dt.datetime(2013,1,1,0,5,0),dt.datetime(2013,1,31)],\n",
    "                                 only_checked=True,clear=False,plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from previous day\n",
    "Under the assumption that \"The best prediction for tomorrows weather is todays weather\", one can also replace missing data by making use of (one of) the previous days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:55:06.731819",
     "start_time": "2017-05-09T11:55:06.018568+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.fill_missing_daybefore('CODtot_line2',\n",
    "                               [dt.datetime(2013,1,25),dt.datetime(2013,1,27)],\n",
    "                               range_to_replace=[0,10],plot=True,\n",
    "                               only_checked=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:55:07.431337",
     "start_time": "2017-05-09T11:55:06.734413+02:00"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = dataset.plot_analysed('CODtot_line2')\n",
    "ax.legend(bbox_to_anchor=(1.3,1.0),fontsize=18)\n",
    "ax.set_ylabel('Total COD [mg/L]',fontsize=18);ax.set_xlabel('')\n",
    "ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the daily average of a certain data series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:55:07.830400",
     "start_time": "2017-05-09T11:55:07.433945+02:00"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.calc_daily_average('CODtot_line2',arange=[dt.datetime(2013,1,1),dt.datetime(2013,2,1)],plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the proportional concentration of different flows coming together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T09:55:07.842239",
     "start_time": "2017-05-09T11:55:07.833046+02:00"
    }
   },
   "outputs": [],
   "source": [
    "dataset.calc_total_proportional('Flow_total',\n",
    "                                ['Flow_line1','Flow_line2','Flow_line3'],\n",
    "                                ['TSS_line1','TSS_line2','TSS_line3'],\n",
    "                               'TSS_prop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "282px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
